import streamlit as st
import boto3
import pandas as pd
import time

# --- CONFIGURATION ---
# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö AWS Account ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì
DATABASE_NAME = 'nyctaxi_dev_db_catalog'
TABLE_NAME = 'processed-all_rides'
S3_OUTPUT_BUCKET = 's3://nyctaxi-dev-datalake-0116/athena/'
AWS_REGION = 'ap-southeast-1'

# --- PAGE SETUP ---
st.set_page_config(page_title="NYC Taxi Analytics", layout="wide")

st.title("üöñ NYC Taxi Data Platform")
st.markdown("Dashboard ‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏≤‡∏£‡πÄ‡∏î‡∏¥‡∏ô‡∏ó‡∏≤‡∏á Taxi ‡πÉ‡∏ô New York (Data Pipeline by Airflow)")

# --- SIDEBAR (‡πÄ‡∏°‡∏ô‡∏π‡πÄ‡∏•‡∏∑‡∏≠‡∏Å) ---
with st.sidebar:
    st.header("üìÖ ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")
    selected_year = st.selectbox("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏õ‡∏µ", ["2024"])
    selected_month = st.selectbox("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏î‡∏∑‡∏≠‡∏ô", ["January", "February", "March"])
    
    st.markdown("---")
    st.caption("‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏£‡∏∞‡∏ö‡∏ö: üü¢ Online")

# --- FUNCTIONS ---
def query_athena(query):
    """‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏¢‡∏¥‡∏á SQL ‡πÑ‡∏õ‡∏´‡∏≤ Athena"""
    client = boto3.client('athena', region_name=AWS_REGION)
    
    # 1. ‡∏™‡πà‡∏á‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á Query
    response = client.start_query_execution(
        QueryString=query,
        QueryExecutionContext={'Database': DATABASE_NAME},
        ResultConfiguration={'OutputLocation': S3_OUTPUT_BUCKET}
    )
    query_execution_id = response['QueryExecutionId']
    
    # 2. ‡∏£‡∏≠‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå (Polling)
    with st.spinner('‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å Data Lake...'):
        while True:
            stats = client.get_query_execution(QueryExecutionId=query_execution_id)
            status = stats['QueryExecution']['Status']['State']
            if status in ['SUCCEEDED', 'FAILED', 'CANCELLED']:
                break
            time.sleep(1)
    
    # 3. ‡∏≠‡πà‡∏≤‡∏ô‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
    if status == 'SUCCEEDED':
        results = client.get_query_results(QueryExecutionId=query_execution_id)
        # ‡πÅ‡∏õ‡∏•‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÄ‡∏õ‡πá‡∏ô Pandas DataFrame (‡πÅ‡∏ö‡∏ö‡∏¢‡πà‡∏≠)
        # ‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏: ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ô‡∏µ‡πâ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏°‡πà‡πÄ‡∏¢‡∏≠‡∏∞‡∏°‡∏≤‡∏Å ‡∏ñ‡πâ‡∏≤‡πÄ‡∏¢‡∏≠‡∏∞‡∏Ñ‡∏ß‡∏£‡πÉ‡∏ä‡πâ s3 select ‡∏´‡∏£‡∏∑‡∏≠ awswrangler
        columns = [col['Label'] for col in results['ResultSet']['ResultSetMetadata']['ColumnInfo']]
        rows = []
        for row in results['ResultSet']['Rows'][1:]:
            rows.append([field.get('VarCharValue', None) for field in row['Data']])
        
        df = pd.DataFrame(rows, columns=columns)
        return df
    else:
        # ‡∏î‡∏∂‡∏á‡∏™‡∏≤‡πÄ‡∏´‡∏ï‡∏∏‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏≠‡∏≠‡∏Å‡∏°‡∏≤‡πÇ‡∏ä‡∏ß‡πå
        error_reason = stats['QueryExecution']['Status'].get('StateChangeReason', 'Unknown Error')
        st.error(f"Query Failed: {status}")
        st.error(f"Reason: {error_reason}") # <--- ‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ô‡∏µ‡πâ‡∏à‡∏∞‡∏ö‡∏≠‡∏Å‡πÉ‡∏ö‡πâ‡πÄ‡∏£‡∏≤
        return None

# --- MAIN CONTENT ---

# ‡∏™‡∏£‡πâ‡∏≤‡∏á Tab ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÅ‡∏¢‡∏Å‡∏™‡πà‡∏ß‡∏ô‡∏î‡∏π‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‡∏Å‡∏±‡∏ö ‡∏™‡πà‡∏ß‡∏ô‡∏™‡∏±‡πà‡∏á‡∏á‡∏≤‡∏ô
tab1, tab2 = st.tabs(["üìä Analytics Dashboard", "‚öôÔ∏è Control Plane"])

with tab1:
    st.subheader(f"‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏õ‡∏£‡∏∞‡∏à‡∏≥‡πÄ‡∏î‡∏∑‡∏≠‡∏ô: {selected_month} {selected_year}")
    
    if st.button("üîÑ ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î", type="primary"):
        # SQL Query (‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏£‡∏∏‡∏õ)
        sql = f"""
            SELECT type, count(*) as rides 
            FROM "{DATABASE_NAME}"."{TABLE_NAME}" 
            GROUP BY type 
            ORDER BY rides DESC
        """
        
        df = query_athena(sql)
        
        if df is not None and not df.empty:
            # ‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç
            df['rides'] = df['rides'].astype(int)
            
            # ‡πÅ‡∏™‡∏î‡∏á Metric
            total_rides = df['rides'].sum()
            col1, col2, col3 = st.columns(3)
            col1.metric("Total Rides", f"{total_rides:,}")
            col2.metric("Top Type", df.iloc[0]['type'])
            col3.metric("Data Source", "Amazon S3 (Parquet)")
            
            # ‡πÅ‡∏™‡∏î‡∏á‡∏Å‡∏£‡∏≤‡∏ü‡πÅ‡∏•‡∏∞‡∏ï‡∏≤‡∏£‡∏≤‡∏á
            c1, c2 = st.columns([2, 1])
            with c1:
                st.caption("‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏ß‡πÅ‡∏ö‡πà‡∏á‡∏ï‡∏≤‡∏°‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏£‡∏ñ")
                st.bar_chart(df.set_index('type'), color="#FF4B4B")
            with c2:
                st.caption("‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡∏¥‡∏ö")
                st.dataframe(df, hide_index=True)
        else:
            st.warning("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‡∏´‡∏£‡∏∑‡∏≠‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ô Pipeline")

with tab2:
    st.subheader("‡∏™‡∏±‡πà‡∏á‡∏á‡∏≤‡∏ô Data Pipeline (Airflow)")
    st.info("‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡∏ô‡∏µ‡πâ‡∏à‡∏∞‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ö Airflow API ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡∏±‡πà‡∏á Trigger DAG ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡πÉ‡∏´‡∏°‡πà (Coming Soon)")
    if st.button("‚ñ∂Ô∏è Start Pipeline for selected month"):
        st.toast("‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏ñ‡∏π‡∏Å‡∏™‡πà‡∏á‡πÑ‡∏õ‡∏¢‡∏±‡∏á Airflow ‡πÅ‡∏•‡πâ‡∏ß! (Simulation)")